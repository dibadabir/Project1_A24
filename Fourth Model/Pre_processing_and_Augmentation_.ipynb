{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAHkuNk7-8Ig",
        "outputId": "aa0eaa30-d2ce-41b3-8775-47c14c784d4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder /content/drive/MyDrive/Augmented Non Cancerous /vasc/over_30 initially has 115 images after hair removal preprocessing.\n",
            "/content/drive/MyDrive/Augmented Non Cancerous /vasc/over_30: 150 images generated.\n",
            "/content/drive/MyDrive/Augmented Non Cancerous /vasc/over_30: 200 images generated.\n",
            "/content/drive/MyDrive/Augmented Non Cancerous /vasc/over_30: 250 images generated.\n",
            "/content/drive/MyDrive/Augmented Non Cancerous /vasc/over_30: 300 images generated.\n",
            "/content/drive/MyDrive/Augmented Non Cancerous /vasc/over_30: 350 images generated.\n",
            "/content/drive/MyDrive/Augmented Non Cancerous /vasc/over_30: 400 images generated.\n",
            "/content/drive/MyDrive/Augmented Non Cancerous /vasc/over_30: 450 images generated.\n",
            "/content/drive/MyDrive/Augmented Non Cancerous /vasc/over_30: 500 images generated.\n",
            "After augmentation, folder /content/drive/MyDrive/Augmented Non Cancerous /vasc/over_30 has 500 images.\n",
            "\n",
            "Folder /content/drive/MyDrive/Augmented Non Cancerous /vasc/30_and_under initially has 27 images after hair removal preprocessing.\n",
            "/content/drive/MyDrive/Augmented Non Cancerous /vasc/30_and_under: 50 images generated.\n",
            "/content/drive/MyDrive/Augmented Non Cancerous /vasc/30_and_under: 100 images generated.\n",
            "/content/drive/MyDrive/Augmented Non Cancerous /vasc/30_and_under: 150 images generated.\n",
            "/content/drive/MyDrive/Augmented Non Cancerous /vasc/30_and_under: 200 images generated.\n",
            "/content/drive/MyDrive/Augmented Non Cancerous /vasc/30_and_under: 250 images generated.\n",
            "/content/drive/MyDrive/Augmented Non Cancerous /vasc/30_and_under: 300 images generated.\n",
            "/content/drive/MyDrive/Augmented Non Cancerous /vasc/30_and_under: 350 images generated.\n",
            "/content/drive/MyDrive/Augmented Non Cancerous /vasc/30_and_under: 400 images generated.\n",
            "/content/drive/MyDrive/Augmented Non Cancerous /vasc/30_and_under: 450 images generated.\n",
            "/content/drive/MyDrive/Augmented Non Cancerous /vasc/30_and_under: 500 images generated.\n",
            "After augmentation, folder /content/drive/MyDrive/Augmented Non Cancerous /vasc/30_and_under has 500 images.\n",
            "\n",
            "Folder /content/drive/MyDrive/Augmented Non Cancerous /nv/over_30 initially has 1879 images after hair removal preprocessing.\n",
            "After augmentation, folder /content/drive/MyDrive/Augmented Non Cancerous /nv/over_30 has 1879 images.\n",
            "\n",
            "Folder /content/drive/MyDrive/Augmented Non Cancerous /nv/over_30 has 1879 images, removing extra to maintain 500.\n",
            "Folder /content/drive/MyDrive/Augmented Non Cancerous /nv/over_30 now has exactly 500 images.\n",
            "\n",
            "Folder /content/drive/MyDrive/Augmented Non Cancerous /nv/30_and_under initially has 490 images after hair removal preprocessing.\n",
            "/content/drive/MyDrive/Augmented Non Cancerous /nv/30_and_under: 500 images generated.\n",
            "After augmentation, folder /content/drive/MyDrive/Augmented Non Cancerous /nv/30_and_under has 500 images.\n",
            "\n",
            "Folder /content/drive/MyDrive/Augmented Non Cancerous /df/over_30 initially has 116 images after hair removal preprocessing.\n",
            "/content/drive/MyDrive/Augmented Non Cancerous /df/over_30: 150 images generated.\n",
            "/content/drive/MyDrive/Augmented Non Cancerous /df/over_30: 200 images generated.\n",
            "/content/drive/MyDrive/Augmented Non Cancerous /df/over_30: 250 images generated.\n",
            "/content/drive/MyDrive/Augmented Non Cancerous /df/over_30: 300 images generated.\n",
            "/content/drive/MyDrive/Augmented Non Cancerous /df/over_30: 350 images generated.\n",
            "/content/drive/MyDrive/Augmented Non Cancerous /df/over_30: 400 images generated.\n",
            "/content/drive/MyDrive/Augmented Non Cancerous /df/over_30: 450 images generated.\n",
            "/content/drive/MyDrive/Augmented Non Cancerous /df/over_30: 500 images generated.\n",
            "After augmentation, folder /content/drive/MyDrive/Augmented Non Cancerous /df/over_30 has 500 images.\n",
            "\n",
            "Folder /content/drive/MyDrive/Augmented Non Cancerous /df/30_and_under initially has 6 images after hair removal preprocessing.\n",
            "/content/drive/MyDrive/Augmented Non Cancerous /df/30_and_under: 50 images generated.\n",
            "/content/drive/MyDrive/Augmented Non Cancerous /df/30_and_under: 100 images generated.\n",
            "/content/drive/MyDrive/Augmented Non Cancerous /df/30_and_under: 150 images generated.\n",
            "/content/drive/MyDrive/Augmented Non Cancerous /df/30_and_under: 200 images generated.\n",
            "/content/drive/MyDrive/Augmented Non Cancerous /df/30_and_under: 250 images generated.\n",
            "/content/drive/MyDrive/Augmented Non Cancerous /df/30_and_under: 300 images generated.\n",
            "/content/drive/MyDrive/Augmented Non Cancerous /df/30_and_under: 350 images generated.\n",
            "/content/drive/MyDrive/Augmented Non Cancerous /df/30_and_under: 400 images generated.\n",
            "/content/drive/MyDrive/Augmented Non Cancerous /df/30_and_under: 450 images generated.\n",
            "/content/drive/MyDrive/Augmented Non Cancerous /df/30_and_under: 500 images generated.\n",
            "After augmentation, folder /content/drive/MyDrive/Augmented Non Cancerous /df/30_and_under has 500 images.\n",
            "\n",
            "Folder /content/drive/MyDrive/Augmented Non Cancerous /bkl/over_30 initially has 525 images after hair removal preprocessing.\n",
            "After augmentation, folder /content/drive/MyDrive/Augmented Non Cancerous /bkl/over_30 has 525 images.\n",
            "\n",
            "Folder /content/drive/MyDrive/Augmented Non Cancerous /bkl/over_30 has 525 images, removing extra to maintain 500.\n",
            "Folder /content/drive/MyDrive/Augmented Non Cancerous /bkl/over_30 now has exactly 500 images.\n",
            "\n",
            "Folder /content/drive/MyDrive/Augmented Non Cancerous /bkl/30_and_under initially has 9 images after hair removal preprocessing.\n",
            "/content/drive/MyDrive/Augmented Non Cancerous /bkl/30_and_under: 50 images generated.\n",
            "/content/drive/MyDrive/Augmented Non Cancerous /bkl/30_and_under: 100 images generated.\n",
            "/content/drive/MyDrive/Augmented Non Cancerous /bkl/30_and_under: 150 images generated.\n",
            "/content/drive/MyDrive/Augmented Non Cancerous /bkl/30_and_under: 200 images generated.\n",
            "/content/drive/MyDrive/Augmented Non Cancerous /bkl/30_and_under: 250 images generated.\n",
            "/content/drive/MyDrive/Augmented Non Cancerous /bkl/30_and_under: 300 images generated.\n",
            "/content/drive/MyDrive/Augmented Non Cancerous /bkl/30_and_under: 350 images generated.\n",
            "/content/drive/MyDrive/Augmented Non Cancerous /bkl/30_and_under: 400 images generated.\n",
            "/content/drive/MyDrive/Augmented Non Cancerous /bkl/30_and_under: 450 images generated.\n",
            "/content/drive/MyDrive/Augmented Non Cancerous /bkl/30_and_under: 500 images generated.\n",
            "After augmentation, folder /content/drive/MyDrive/Augmented Non Cancerous /bkl/30_and_under has 500 images.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator, array_to_img\n",
        "\n",
        "# Define paths for original and augmented data\n",
        "main_dir = \"/content/drive/MyDrive/Discipline Specific /4th Model/Original Non-cancerous\"\n",
        "aug_main_dir = \"/content/drive/MyDrive/Preprocessed Non Cancerous  \"\n",
        "\n",
        "# Define the classes and age groups\n",
        "classes = ['vasc', 'nv', 'df', 'bkl']\n",
        "age_groups = [\"over_30\", \"30_and_under\"]\n",
        "\n",
        "# Target number of images per sub-folder\n",
        "target_num = 500\n",
        "\n",
        "# Define ImageDataGenerator for augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\"\n",
        ")\n",
        "\n",
        "# Function to remove hair from lesions before augmentation\n",
        "def remove_hair_direct_replace(image, blackhat_kernel_size=(9, 9), blackhat_threshold=10, inpaint_radius=1):\n",
        "    \"\"\"Removes hair from the image while preserving original color in non-hair areas.\"\"\"\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Blackhat transform to highlight hair\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, blackhat_kernel_size)\n",
        "    blackhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, kernel)\n",
        "\n",
        "    # Threshold to create binary mask\n",
        "    _, hair_mask = cv2.threshold(blackhat, blackhat_threshold, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Morphological opening to remove noise\n",
        "    open_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
        "    hair_mask = cv2.morphologyEx(hair_mask, cv2.MORPH_OPEN, open_kernel)\n",
        "\n",
        "    # Dilation to ensure hair is fully covered\n",
        "    dilate_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
        "    hair_mask = cv2.dilate(hair_mask, dilate_kernel, iterations=1)\n",
        "\n",
        "    # Inpaint hair regions\n",
        "    inpainted = cv2.inpaint(image, hair_mask, inpaint_radius, flags=cv2.INPAINT_TELEA)\n",
        "\n",
        "    # Replace only hair pixels with inpainted pixels\n",
        "    hair_mask_bool = hair_mask.astype(bool)\n",
        "    result = image.copy()\n",
        "    result[hair_mask_bool] = inpainted[hair_mask_bool]\n",
        "\n",
        "    return result\n",
        "\n",
        "# Process each class and age group folder\n",
        "for cls in classes:\n",
        "    for age in age_groups:\n",
        "        src_dir = os.path.join(main_dir, cls, age)  # Source folder\n",
        "        dest_dir = os.path.join(aug_main_dir, cls, age)  # Destination folder\n",
        "        os.makedirs(dest_dir, exist_ok=True)\n",
        "\n",
        "        # Get list of image files\n",
        "        image_files = [f for f in os.listdir(src_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "        # Copy and preprocess original images\n",
        "        for f in image_files:\n",
        "            src_path = os.path.join(src_dir, f)\n",
        "            dest_path = os.path.join(dest_dir, f)\n",
        "\n",
        "            # Load image with OpenCV\n",
        "            image = cv2.imread(src_path)\n",
        "\n",
        "            # Remove hair from the image\n",
        "            hair_free_image = remove_hair_direct_replace(image)\n",
        "\n",
        "            # Save the preprocessed image to the destination folder\n",
        "            cv2.imwrite(dest_path, hair_free_image)\n",
        "\n",
        "        # Count images currently in the destination folder\n",
        "        count = len(os.listdir(dest_dir))\n",
        "        print(f\"Folder {dest_dir} initially has {count} images after hair removal preprocessing.\")\n",
        "\n",
        "        # Skip augmentation if no original images are present\n",
        "        if len(image_files) == 0:\n",
        "            print(f\"No images found in {src_dir}. Skipping augmentation for this folder.\")\n",
        "            continue\n",
        "\n",
        "        # Index for naming augmented images\n",
        "        augment_index = 0\n",
        "\n",
        "        # Generate augmented images until the folder reaches target_num images\n",
        "        while count < target_num:\n",
        "            for f in image_files:\n",
        "                if count >= target_num:\n",
        "                    break  # Stop if target reached\n",
        "\n",
        "                img_path = os.path.join(dest_dir, f)  # Use preprocessed image path\n",
        "                img = load_img(img_path)  # Load preprocessed image\n",
        "                x = img_to_array(img)  # Convert to numpy array\n",
        "                x = x.reshape((1,) + x.shape)  # Reshape for ImageDataGenerator\n",
        "\n",
        "                # Generate augmented image\n",
        "                augmented = next(datagen.flow(x, batch_size=1))[0].astype(np.uint8)\n",
        "\n",
        "                # Create a unique filename\n",
        "                aug_filename = f\"aug_{os.path.splitext(f)[0]}_{augment_index}.jpg\"\n",
        "                aug_dest_path = os.path.join(dest_dir, aug_filename)\n",
        "\n",
        "                # Save augmented image\n",
        "                array_to_img(augmented).save(aug_dest_path)\n",
        "\n",
        "                count += 1\n",
        "                augment_index += 1\n",
        "\n",
        "                # Optional: Print progress every 50 images\n",
        "                if count % 50 == 0:\n",
        "                    print(f\"{dest_dir}: {count} images generated.\")\n",
        "\n",
        "        print(f\"After augmentation, folder {dest_dir} has {count} images.\\n\")\n",
        "\n",
        "        # Remove extra images if the folder exceeds the target limit\n",
        "        if count > target_num:\n",
        "            print(f\"Folder {dest_dir} has {count} images, removing extra to maintain {target_num}.\")\n",
        "\n",
        "            # Get list of all images in the folder\n",
        "            all_images = [os.path.join(dest_dir, f) for f in os.listdir(dest_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "            # Randomly shuffle the images\n",
        "            random.shuffle(all_images)\n",
        "\n",
        "            # Remove extra images\n",
        "            num_to_remove = count - target_num\n",
        "            for i in range(num_to_remove):\n",
        "                os.remove(all_images[i])\n",
        "\n",
        "            print(f\"Folder {dest_dir} now has exactly {target_num} images.\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## New BKL Folder made because of low recall with the previous one"
      ],
      "metadata": {
        "id": "I-z0jN3c_OAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def remove_hair_direct_replace(\n",
        "    image,\n",
        "    blackhat_kernel_size=(9, 9),\n",
        "    blackhat_threshold=10,\n",
        "    inpaint_radius=1\n",
        "):\n",
        "    \"\"\"\n",
        "    Removes hair from the image by:\n",
        "      1. Detecting hair regions using blackhat + threshold + morphological ops.\n",
        "      2. Inpainting only those regions.\n",
        "      3. Directly replacing hair pixels in the original image with inpainted pixels,\n",
        "         preserving the original color in non-hair areas.\n",
        "    \"\"\"\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Blackhat to highlight hair\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, blackhat_kernel_size)\n",
        "    blackhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, kernel)\n",
        "\n",
        "    # Threshold to create a binary mask\n",
        "    _, hair_mask = cv2.threshold(blackhat, blackhat_threshold, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Morphological opening (remove small noise)\n",
        "    open_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
        "    hair_mask = cv2.morphologyEx(hair_mask, cv2.MORPH_OPEN, open_kernel)\n",
        "\n",
        "    # Dilate to ensure thin hair strands are fully covered\n",
        "    dilate_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
        "    hair_mask = cv2.dilate(hair_mask, dilate_kernel, iterations=1)\n",
        "\n",
        "    # Inpaint the image in hair regions\n",
        "    inpainted = cv2.inpaint(image, hair_mask, inpaint_radius, flags=cv2.INPAINT_TELEA)\n",
        "\n",
        "    # Convert hair_mask to boolean for indexing\n",
        "    hair_mask_bool = hair_mask.astype(bool)\n",
        "\n",
        "    # Create a copy of the original image\n",
        "    result = image.copy()\n",
        "\n",
        "    # Directly replace hair pixels in 'result' with the inpainted pixels\n",
        "    result[hair_mask_bool] = inpainted[hair_mask_bool]\n",
        "\n",
        "    return result\n",
        "\n",
        "# Set up image augmentation parameters\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "def augment_images(source_folder, target_folder, target_count=500):\n",
        "    \"\"\"\n",
        "    Augments images from source_folder and saves the augmented images to target_folder.\n",
        "    To ensure diversity, the code shuffles the list of available images and processes them\n",
        "    one at a time in cycles until the total number of augmented images reaches target_count.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(target_folder):\n",
        "        os.makedirs(target_folder)\n",
        "\n",
        "    # Look for common image file formats\n",
        "    valid_ext = [\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\"]\n",
        "    image_files = [os.path.join(source_folder, f) for f in os.listdir(source_folder)\n",
        "                   if os.path.splitext(f)[1].lower() in valid_ext]\n",
        "\n",
        "    if len(image_files) == 0:\n",
        "        print(\"No images found in\", source_folder)\n",
        "        return\n",
        "\n",
        "    augmented_count = 0\n",
        "    cycle = 0\n",
        "    while augmented_count < target_count:\n",
        "        # Shuffle the image list each cycle for diversity\n",
        "        random.shuffle(image_files)\n",
        "        for image_path in image_files:\n",
        "            if augmented_count >= target_count:\n",
        "                break\n",
        "            image = cv2.imread(image_path)\n",
        "            if image is None:\n",
        "                continue\n",
        "\n",
        "            # Pre-process image: remove hair\n",
        "            image_preprocessed = remove_hair_direct_replace(image)\n",
        "\n",
        "            # Prepare image for augmentation (expand dimensions to match generator input)\n",
        "            image_array = np.expand_dims(image_preprocessed, 0)\n",
        "\n",
        "            # Generate one augmented image for this original image\n",
        "            aug_iter = datagen.flow(image_array, batch_size=1)\n",
        "            aug_image = next(aug_iter)[0].astype(np.uint8)\n",
        "\n",
        "            # Construct a unique filename for the augmented image\n",
        "            filename = os.path.basename(image_path)\n",
        "            name, _ = os.path.splitext(filename)\n",
        "            save_path = os.path.join(target_folder, f\"{name}_aug_cycle{cycle}_{augmented_count}.png\")\n",
        "            cv2.imwrite(save_path, aug_image)\n",
        "            print(f\"Saved {save_path}\")\n",
        "            augmented_count += 1\n",
        "        cycle += 1\n",
        "    print(f\"Augmentation complete: {augmented_count} images saved in {target_folder}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Update these paths to match your Google Drive folder structure.\n",
        "    base_drive_folder = \"/content/drive/MyDrive/Discipline Specific /4th Model/Original Non-cancerous/bkl\"  # Folder containing subfolders \"over_30\" and \"30_and_under\"\n",
        "    target_drive_folder = \"/content/drive/MyDrive/Discipline Specific /4th Model/New BKL\"  # New folder to store augmented images\n",
        "\n",
        "    # Define the two subfolder names\n",
        "    subfolders = [\"over_30\", \"30_and_under\"]\n",
        "\n",
        "    for sub in subfolders:\n",
        "        source_path = os.path.join(base_drive_folder, sub)\n",
        "        target_path = os.path.join(target_drive_folder, sub)\n",
        "        print(f\"Augmenting images in {source_path}...\")\n",
        "        augment_images(source_path, target_path, target_count=500)"
      ],
      "metadata": {
        "id": "ga83wy69_Noh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}