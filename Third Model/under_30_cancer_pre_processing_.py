# -*- coding: utf-8 -*-
"""Under 30 Cancer pre processing .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/180jY6XxpwnjuN0I93Aw-6fm29-pWiKV6
"""

import pandas as pd
import os
import shutil


# drive.mount('/content/drive')

#Load the CSV metadata
csv_path = '/content/drive/MyDrive/ Discipline-specific/Skin cancer dataset /dataverse_files/HAM10000_metadata.csv'
df = pd.read_csv(csv_path)

# Optionally, clean the 'dx' column to remove extra spaces
#df['dx'] = df['dx'].str.strip()

# 2. Set the age threshold (images from patients aged ≤ 30)
age_threshold = 30
filtered_df = df[df['age'] <= age_threshold]

# 3. Define the diagnosis types and the source folders where the original images are stored.
# Update these paths if your original images are stored elsewhere.
source_dirs = {
    'bcc': '/content/drive/MyDrive/ Discipline-specific/Organised Images/bcc',
    'mel': '/content/drive/MyDrive/ Discipline-specific/Organised Images/mel',
    'akiec': '/content/drive/MyDrive/ Discipline-specific/Organised Images/akiec'
}

# 4. Define the destination base folder where new folders will be created
dest_base = '/content/drive/MyDrive/Discipline-specific/Organised Images Cancerous under 30'

# 5. Loop over each diagnosis type, create a new folder (e.g., "bcc_under30"), and copy images
for dx in ['bcc', 'mel', 'akiec']:
    # Create a new destination folder (e.g., "mel_under30")
    dest_folder = os.path.join(dest_base, f"{dx}_under30")
    os.makedirs(dest_folder, exist_ok=True)

    # Filter the metadata for the current diagnosis type
    dx_df = filtered_df[filtered_df['dx'] == dx]
    print(f"For diagnosis '{dx}', found {len(dx_df)} images with age ≤ {age_threshold}.")

    # Loop through each image_id and copy the image from the source to the new folder
    for image_id in dx_df['image_id']:
        # Assuming image files have a .jpg extension; adjust if necessary
        src_path = os.path.join(source_dirs[dx], f"{image_id}.jpg")
        dest_path = os.path.join(dest_folder, f"{image_id}.jpg")

        if os.path.exists(src_path):
            shutil.copy(src_path, dest_path)
            print(f"Copied {src_path} to {dest_path}")
        else:
            print(f"File not found: {src_path}")

"""Pre processing for akiec"""

import cv2
import numpy as np
import os
from tqdm import tqdm

def remove_hair_dullrazor(image):
    """
    Removes hair from the input image using the classic DullRazor method.

    Steps:
      1. Convert to grayscale.
      2. Use a blackhat morphological operation to highlight hair regions.
      3. Threshold to create a hair mask.
      4. Inpaint hair regions using cv2.INPAINT_TELEA.

    Parameters:
      - image: Input BGR image.

    Returns:
      - The image with hair removed.
    """
    # Convert to grayscale
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # Blackhat operation to reveal hair features
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (17, 17))
    blackhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, kernel)

    # Threshold the blackhat image to create a binary hair mask
    _, hair_mask = cv2.threshold(blackhat, 10, 255, cv2.THRESH_BINARY)

    # Inpaint to remove the hair regions from the original image
    # Changed inpaintRadius from 3 to 1 to reduce the area affected by inpainting
    inpainted_image = cv2.inpaint(image, hair_mask, inpaintRadius=1, flags=cv2.INPAINT_TELEA)

    return inpainted_image

def process_and_save_images(input_folder, output_folder):
    """
    Processes all images in the input folder using the DullRazor hair removal method,
    resizes them to 224x224, and saves the results in the output folder.
    """
    os.makedirs(output_folder, exist_ok=True)
    valid_extensions = ('.jpg', '.jpeg', '.png')
    image_files = [f for f in os.listdir(input_folder) if f.lower().endswith(valid_extensions)]

    for image_file in tqdm(image_files, desc="Processing Images"):
        input_path = os.path.join(input_folder, image_file)
        output_path = os.path.join(output_folder, image_file)

        # Read the image
        image = cv2.imread(input_path)
        if image is None:
            print(f"Error reading image: {image_file}. Skipping...")
            continue

        # Remove hair using the DullRazor algorithm
        processed_image = remove_hair_dullrazor(image)

        # Resize the image to 224x224 pixels
        processed_image = cv2.resize(processed_image, (224, 224), interpolation=cv2.INTER_AREA)

        # Save the processed image
        cv2.imwrite(output_path, processed_image)

# Fixed input and output folder paths
input_folder = "/content/drive/MyDrive/Discipline-specific/Organised Images Cancerous under 30/akiec_under30"
output_folder = "/content/drive/MyDrive/Discipline-specific/Organised Images Cancerous under 30/akiec_under30_pre-processed"

process_and_save_images(input_folder, output_folder)
print("Image preprocessing complete!")

"""Pre processig for mel"""

import cv2
import numpy as np
import os
from tqdm import tqdm

def remove_hair_dullrazor(image):
    """
    Removes hair from the input image using the classic DullRazor method.

    Steps:
      1. Convert to grayscale.
      2. Use a blackhat morphological operation to highlight hair regions.
      3. Threshold to create a hair mask.
      4. Inpaint hair regions using cv2.INPAINT_TELEA.

    Parameters:
      - image: Input BGR image.

    Returns:
      - The image with hair removed.
    """
    # Convert to grayscale
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # Blackhat operation to reveal hair features
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (17, 17))
    blackhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, kernel)

    # Threshold the blackhat image to create a binary hair mask
    _, hair_mask = cv2.threshold(blackhat, 10, 255, cv2.THRESH_BINARY)

    # Inpaint to remove the hair regions from the original image
    # Changed inpaintRadius from 3 to 1 to reduce the area affected by inpainting
    inpainted_image = cv2.inpaint(image, hair_mask, inpaintRadius=1, flags=cv2.INPAINT_TELEA)

    return inpainted_image

def process_and_save_images(input_folder, output_folder):
    """
    Processes all images in the input folder using the DullRazor hair removal method,
    resizes them to 224x224, and saves the results in the output folder.
    """
    os.makedirs(output_folder, exist_ok=True)
    valid_extensions = ('.jpg', '.jpeg', '.png')
    image_files = [f for f in os.listdir(input_folder) if f.lower().endswith(valid_extensions)]

    for image_file in tqdm(image_files, desc="Processing Images"):
        input_path = os.path.join(input_folder, image_file)
        output_path = os.path.join(output_folder, image_file)

        # Read the image
        image = cv2.imread(input_path)
        if image is None:
            print(f"Error reading image: {image_file}. Skipping...")
            continue

        # Remove hair using the DullRazor algorithm
        processed_image = remove_hair_dullrazor(image)

        # Resize the image to 224x224 pixels
        processed_image = cv2.resize(processed_image, (224, 224), interpolation=cv2.INTER_AREA)

        # Save the processed image
        cv2.imwrite(output_path, processed_image)

# Fixed input and output folder paths
input_folder = "/content/drive/MyDrive/Discipline-specific/Organised Images Cancerous under 30/mel_under30"
output_folder = "/content/drive/MyDrive/Discipline-specific/Organised Images Cancerous under 30/mel_under30_pre-processed"

process_and_save_images(input_folder, output_folder)
print("Image preprocessing complete!")

import cv2
import numpy as np
import os
from tqdm import tqdm

def remove_hair_direct_replace(
    image,
    blackhat_kernel_size=(9, 9),
    blackhat_threshold=10,
    inpaint_radius=1
):
    """
    Removes hair from the image by:
      1. Detecting hair regions using blackhat + threshold + morphological ops.
      2. Inpainting only those regions.
      3. Directly replacing hair pixels in the original image with inpainted pixels,
         preserving the original color in non-hair areas.
    """
    # Convert to grayscale
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # Blackhat to highlight hair
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, blackhat_kernel_size)
    blackhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, kernel)

    # Threshold to create a binary mask
    _, hair_mask = cv2.threshold(blackhat, blackhat_threshold, 255, cv2.THRESH_BINARY)

    # Morphological opening (remove small noise)
    open_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
    hair_mask = cv2.morphologyEx(hair_mask, cv2.MORPH_OPEN, open_kernel)

    # Dilate to ensure thin hair strands are fully covered
    dilate_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
    hair_mask = cv2.dilate(hair_mask, dilate_kernel, iterations=1)

    # Inpaint the image in hair regions
    inpainted = cv2.inpaint(image, hair_mask, inpaint_radius, flags=cv2.INPAINT_TELEA)

    # Convert hair_mask to boolean for indexing
    hair_mask_bool = hair_mask.astype(bool)

    # Create a copy of the original image
    result = image.copy()

    # Directly replace hair pixels in 'result' with the inpainted pixels
    result[hair_mask_bool] = inpainted[hair_mask_bool]

    return result

def process_and_save_images(input_folder, output_folder):
    """
    Processes all images in the input folder by removing hair via direct replacement,
    resizing them to 224x224, and saving the results in the output folder.
    """
    os.makedirs(output_folder, exist_ok=True)
    valid_extensions = ('.jpg', '.jpeg', '.png')
    image_files = [f for f in os.listdir(input_folder) if f.lower().endswith(valid_extensions)]

    for image_file in tqdm(image_files, desc="Processing Images"):
        input_path = os.path.join(input_folder, image_file)
        output_path = os.path.join(output_folder, image_file)

        # Read the image
        image = cv2.imread(input_path)
        if image is None:
            print(f"Error reading image: {image_file}. Skipping...")
            continue

        # Remove hair with direct replacement approach
        processed_image = remove_hair_direct_replace(image)

        # Resize to 224x224
        processed_image = cv2.resize(processed_image, (224, 224), interpolation=cv2.INTER_AREA)

        # Save the processed image
        cv2.imwrite(output_path, processed_image)

# Example usage (adjust paths as needed)
input_folder = "/content/drive/MyDrive/Discipline-specific/Organised Images Cancerous under 30/mel_under30"
output_folder = "/content/drive/MyDrive/Discipline-specific/Organised Images Cancerous under 30/mel_under30_pre-processed"

process_and_save_images(input_folder, output_folder)
print("Image preprocessing complete!")

"""Pre-processing for bcc"""

import cv2
import numpy as np
import os
from tqdm import tqdm

def remove_hair_direct_replace(
    image,
    blackhat_kernel_size=(9, 9),
    blackhat_threshold=10,
    inpaint_radius=1
):
    """
    Removes hair from the image by:
      1. Detecting hair regions using blackhat + threshold + morphological ops.
      2. Inpainting only those regions.
      3. Directly replacing hair pixels in the original image with inpainted pixels,
         preserving the original color in non-hair areas.
    """
    # Convert to grayscale
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # Blackhat to highlight hair
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, blackhat_kernel_size)
    blackhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, kernel)

    # Threshold to create a binary mask
    _, hair_mask = cv2.threshold(blackhat, blackhat_threshold, 255, cv2.THRESH_BINARY)

    # Morphological opening (remove small noise)
    open_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
    hair_mask = cv2.morphologyEx(hair_mask, cv2.MORPH_OPEN, open_kernel)

    # Dilate to ensure thin hair strands are fully covered
    dilate_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
    hair_mask = cv2.dilate(hair_mask, dilate_kernel, iterations=1)

    # Inpaint the image in hair regions
    inpainted = cv2.inpaint(image, hair_mask, inpaint_radius, flags=cv2.INPAINT_TELEA)

    # Convert hair_mask to boolean for indexing
    hair_mask_bool = hair_mask.astype(bool)

    # Create a copy of the original image
    result = image.copy()

    # Directly replace hair pixels in 'result' with the inpainted pixels
    result[hair_mask_bool] = inpainted[hair_mask_bool]

    return result

def process_and_save_images(input_folder, output_folder):
    """
    Processes all images in the input folder by removing hair via direct replacement,
    resizing them to 224x224, and saving the results in the output folder.
    """
    os.makedirs(output_folder, exist_ok=True)
    valid_extensions = ('.jpg', '.jpeg', '.png')
    image_files = [f for f in os.listdir(input_folder) if f.lower().endswith(valid_extensions)]

    for image_file in tqdm(image_files, desc="Processing Images"):
        input_path = os.path.join(input_folder, image_file)
        output_path = os.path.join(output_folder, image_file)

        # Read the image
        image = cv2.imread(input_path)
        if image is None:
            print(f"Error reading image: {image_file}. Skipping...")
            continue

        # Remove hair with direct replacement approach
        processed_image = remove_hair_direct_replace(image)

        # Resize to 224x224
        processed_image = cv2.resize(processed_image, (224, 224), interpolation=cv2.INTER_AREA)

        # Save the processed image
        cv2.imwrite(output_path, processed_image)

# Example usage (adjust paths as needed)
input_folder = "/content/drive/MyDrive/Discipline-specific/Organised Images Cancerous under 30/bcc_under30"
output_folder = "/content/drive/MyDrive/Discipline-specific/Organised Images Cancerous under 30/bcc_under30_pre-processed"

process_and_save_images(input_folder, output_folder)
print("Image preprocessing complete!")

import cv2
import os
from tqdm import tqdm
import numpy as np

def unsharp_mask(image, ksize=(5,5), sigma=1.0, amount=0.5):
    """
    Applies unsharp masking to the image to enhance clarity.

    Parameters:
      - image: Input image.
      - ksize: Kernel size for Gaussian blur.
      - sigma: Standard deviation for Gaussian blur.
      - amount: The strength of the sharpening effect.

    Returns:
      - The sharpened image.
    """
    # Apply Gaussian blur to the image
    blurred = cv2.GaussianBlur(image, ksize, sigma)
    # Combine original and blurred images to create the sharpened image
    sharpened = cv2.addWeighted(image, 1 + amount, blurred, -amount, 0)
    return sharpened

def process_and_save_images(input_folder, output_folder):
    """
    Processes all images in the input folder by resizing them to 224x224,
    applying an unsharp mask for clarity, and saving the results in the output folder.
    """
    os.makedirs(output_folder, exist_ok=True)
    valid_extensions = ('.jpg', '.jpeg', '.png')
    image_files = [f for f in os.listdir(input_folder) if f.lower().endswith(valid_extensions)]

    for image_file in tqdm(image_files, desc="Processing Images"):
        input_path = os.path.join(input_folder, image_file)
        output_path = os.path.join(output_folder, image_file)

        # Read the image
        image = cv2.imread(input_path)
        if image is None:
            print(f"Error reading image: {image_file}. Skipping...")
            continue

        # Resize the image to 224x224 pixels using INTER_AREA interpolation
        resized_image = cv2.resize(image, (224, 224), interpolation=cv2.INTER_AREA)

        # Apply unsharp masking to enhance clarity
        processed_image = unsharp_mask(resized_image, ksize=(5,5), sigma=1.0, amount=0.5)

        # Save the processed image
        cv2.imwrite(output_path, processed_image)

# Fixed input and output folder paths (adjust these paths as needed)
input_folder = "/content/drive/MyDrive/Discipline-specific/Organised Images Cancerous under 30/akiec_under30"
output_folder = "/content/drive/MyDrive/Discipline-specific/Organised Images Cancerous under 30/akiec_under30_pre-processed"

process_and_save_images(input_folder, output_folder)
print("Image preprocessing complete!")

"""Data augmentation for akiec to create 500 images"""

import os
import numpy as np
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array
from tqdm import tqdm

# Specify the directory containing your image(s)
input_dir = "/content/drive/MyDrive/Discipline-specific/Organised Images Cancerous under 30/akiec_under30_pre-processed"

# List all image files in the directory (adjust extensions as needed)
valid_extensions = ('.jpg', '.jpeg', '.png')
image_files = [f for f in os.listdir(input_dir) if f.lower().endswith(valid_extensions)]

if not image_files:
    raise ValueError("No image files found in the directory.")

# Choose one image (for example, the first one)
input_image_path = os.path.join(input_dir, image_files[0])

# Specify the output folder where augmented images will be saved
output_folder = "/content/drive/MyDrive/Discipline-specific/Pre-processed and data augmentated images /akiec"
os.makedirs(output_folder, exist_ok=True)

# Create an ImageDataGenerator with desired augmentations and a fill_mode that avoids streaks:
datagen = ImageDataGenerator(
    horizontal_flip=True,
    vertical_flip=True,
    rotation_range=30,
    zoom_range=0.1,
    width_shift_range=0.05,
    height_shift_range=0.05,
    brightness_range=(0.9, 1.1),
    fill_mode='reflect'  # or 'constant' with cval=0 (for a black background)
)

# Load the input image and convert it to an array
img = load_img(input_image_path)
x = img_to_array(img)
x = np.expand_dims(x, axis=0)  # Reshape to (1, height, width, channels)

# Set the target number of augmented images
target_augmented = 500
generated = 0

# Initialize the generator
aug_generator = datagen.flow(
    x,
    batch_size=1,
    save_to_dir=output_folder,
    save_prefix='aug',
    save_format='jpg'
)

print("Starting data augmentation...")

# Use a while loop to generate augmented images until we reach 500 images.
while generated < target_augmented:
    next(aug_generator)  # Generates and saves 1 new image
    generated += 1
    if generated % 50 == 0:
        print(f"{generated} images generated...")

print(f"Data augmentation complete! Total augmented images: {generated}")

"""data augmentation for mel"""

import os
import math
import numpy as np
from tqdm import tqdm
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array

# Input folder containing your 36 images
input_folder = "/content/drive/MyDrive/Discipline-specific/Organised Images Cancerous under 30/mel_under30_pre-processed"

# Output folder for the 500 augmented images
output_folder = "/content/drive/MyDrive/Discipline-specific/Pre-processed and data augmentated images /mel"
os.makedirs(output_folder, exist_ok=True)

# List all valid image files in the input folder
valid_extensions = ('.jpg', '.jpeg', '.png')
image_files = [f for f in os.listdir(input_folder) if f.lower().endswith(valid_extensions)]

# Check if we have images
num_images = len(image_files)
if num_images == 0:
    raise ValueError("No image files found in the directory.")
print(f"Found {num_images} images.")

# We want exactly 500 augmented images total
target_augmented = 500
# Compute how many augmentations per image (rounding up)
aug_per_image = math.ceil(target_augmented / num_images)
print(f"Each original image will produce up to {aug_per_image} augmented images.")

# Define the data augmentation settings
datagen = ImageDataGenerator(
    horizontal_flip=True,
    vertical_flip=True,
    rotation_range=30,
    zoom_range=0.1,
    width_shift_range=0.05,
    height_shift_range=0.05,
    brightness_range=(0.9, 1.1),
    fill_mode='reflect'  # Avoid streaky edges
)

generated = 0  # Counter for total augmented images

print("Starting data augmentation...")

for image_file in tqdm(image_files, desc="Augmenting each image"):
    if generated >= target_augmented:
        break  # Stop if we've already reached 500

    input_path = os.path.join(input_folder, image_file)

    # Load and convert the image to a NumPy array
    img = load_img(input_path)
    x = img_to_array(img)
    x = np.expand_dims(x, axis=0)  # (1, height, width, channels)

    # Create a flow for this specific image
    aug_generator = datagen.flow(
        x,
        batch_size=1,
        save_to_dir=output_folder,
        save_prefix='aug',
        save_format='jpg'
    )

    # Generate aug_per_image images for this file, or until we hit 500 total
    count_for_this_image = 0
    while count_for_this_image < aug_per_image and generated < target_augmented:
        next(aug_generator)  # This saves one augmented image
        generated += 1
        count_for_this_image += 1

print(f"Data augmentation complete! Total augmented images created: {generated}")

import os
import math
import numpy as np
from tqdm import tqdm
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array

# Input folder containing your 36 images
input_folder = "/content/drive/MyDrive/Discipline-specific/Organised Images Cancerous under 30/bcc_under30_pre-processed"

# Output folder for the 500 augmented images
output_folder = "/content/drive/MyDrive/Discipline-specific/Pre-processed and data augmentated images /bcc"
os.makedirs(output_folder, exist_ok=True)

# List all valid image files in the input folder
valid_extensions = ('.jpg', '.jpeg', '.png')
image_files = [f for f in os.listdir(input_folder) if f.lower().endswith(valid_extensions)]

# Check if we have images
num_images = len(image_files)
if num_images == 0:
    raise ValueError("No image files found in the directory.")
print(f"Found {num_images} images.")

# We want exactly 500 augmented images total
target_augmented = 500
# Compute how many augmentations per image (rounding up)
aug_per_image = math.ceil(target_augmented / num_images)
print(f"Each original image will produce up to {aug_per_image} augmented images.")

# Define the data augmentation settings
datagen = ImageDataGenerator(
    horizontal_flip=True,
    vertical_flip=True,
    rotation_range=30,
    zoom_range=0.1,
    width_shift_range=0.05,
    height_shift_range=0.05,
    brightness_range=(0.9, 1.1),
    fill_mode='reflect'  # Avoid streaky edges
)

generated = 0  # Counter for total augmented images

print("Starting data augmentation...")

for image_file in tqdm(image_files, desc="Augmenting each image"):
    if generated >= target_augmented:
        break  # Stop if we've already reached 500

    input_path = os.path.join(input_folder, image_file)

    # Load and convert the image to a NumPy array
    img = load_img(input_path)
    x = img_to_array(img)
    x = np.expand_dims(x, axis=0)  # (1, height, width, channels)

    # Create a flow for this specific image
    aug_generator = datagen.flow(
        x,
        batch_size=1,
        save_to_dir=output_folder,
        save_prefix='aug',
        save_format='jpg'
    )

    # Generate aug_per_image images for this file, or until we hit 500 total
    count_for_this_image = 0
    while count_for_this_image < aug_per_image and generated < target_augmented:
        next(aug_generator)  # This saves one augmented image
        generated += 1
        count_for_this_image += 1

print(f"Data augmentation complete! Total augmented images created: {generated}")