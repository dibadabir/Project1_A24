# -*- coding: utf-8 -*-
"""Final ResNet50 model cancerous .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MUZEQTtrRQxQghqkGnPed2rUPDsMGetI
"""

import tensorflow as tf
from tensorflow.keras import layers, models, regularizers
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import metrics
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc
from sklearn.preprocessing import label_binarize
from sklearn.utils.class_weight import compute_class_weight
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

def build_resnet50_model(input_shape=(224, 224, 3), num_classes=3, fine_tune_at=170):
    # Load the pre-trained ResNet50 model without its top layers.
    # The model is initialized with ImageNet weights, which provides a robust feature extractor.
    base_model = tf.keras.applications.ResNet50(
        weights='imagenet',
        include_top=False,
        input_shape=input_shape
    )

    # Freeze the layers up to the 'fine_tune_at' index to preserve learned features.
    # Layers before this index will remain unchanged during training.
    for layer in base_model.layers[:fine_tune_at]:
        layer.trainable = False
    # Unfreeze layers starting from 'fine_tune_at' to allow fine-tuning for the current task.
    for layer in base_model.layers[fine_tune_at:]:
        layer.trainable = True

    # Define the input for the new model.
    inputs = tf.keras.Input(shape=input_shape)
    # Apply ResNet50-specific preprocessing (e.g., scaling and mean subtraction) to the input images.
    x = tf.keras.applications.resnet50.preprocess_input(inputs)
    # Pass the preprocessed images through the base model.
    x = base_model(x, training=False)
    # Use Global Average Pooling to reduce the spatial dimensions of the feature maps.
    x = layers.GlobalAveragePooling2D()(x)
    # Introduce dropout to mitigate overfitting; a lower dropout rate is used for milder regularization.
    x = layers.Dropout(0.3)(x)  # Adjusted dropout rate from 0.5 to 0.3 for less aggressive regularization.
    # Add a Dense layer with 256 neurons, using L2 regularization to further control model complexity.
    x = layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(1e-4))(x)  # L2 regularization factor reduced from 1e-3 to 1e-4.
    # Batch Normalization is applied to stabilize and accelerate training.
    x = layers.BatchNormalization()(x)
    # Another dropout layer is added to further guard against overfitting.
    x = layers.Dropout(0.3)(x)  # Maintained a consistent dropout rate for improved regularization.
    # The final Dense layer outputs class probabilities using softmax activation for multi-class classification.
    outputs = layers.Dense(num_classes, activation='softmax')(x)

    # Construct the complete model that includes both the base model and the custom classification head.
    model = models.Model(inputs=inputs, outputs=outputs)
    return model

# Set a fixed initial learning rate for the optimizer.
initial_lr = 5e-4

# Build the ResNet50-based model and compile it with the Adam optimizer.
# The model is compiled with categorical cross-entropy loss and accuracy as a metric.
model = build_resnet50_model(input_shape=(224, 224, 3), num_classes=3, fine_tune_at=170)
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=initial_lr),
              loss='categorical_crossentropy',
              metrics=['accuracy'])
# Display the model architecture and parameter details.
model.summary()

# Configure the training data generator with data augmentation to improve generalization.
train_datagen = ImageDataGenerator(
    rescale=1./255,  # Normalize pixel values to the [0, 1] range.
    rotation_range=15,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.1,
    zoom_range=0.1,
    horizontal_flip=True,
    fill_mode='nearest'
)
# The validation and test data generators only perform rescaling.
val_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

# Load the training data from the specified directory using the augmentation settings.
train_generator = train_datagen.flow_from_directory(
    "/content/drive/MyDrive/Discipline-specific/split_dataset/train",
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)
# Load validation data to monitor model performance during training.
val_generator = val_datagen.flow_from_directory(
    "/content/drive/MyDrive/Discipline-specific/split_dataset/val",
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)
# Load the test data; shuffling is disabled to ensure that the evaluation order remains consistent.
test_generator = test_datagen.flow_from_directory(
    "/content/drive/MyDrive/Discipline-specific/split_dataset/test",
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    shuffle=False
)

# Calculate class weights to balance the training process when classes are imbalanced.
class_weights = compute_class_weight('balanced',
                                     classes=np.unique(train_generator.classes),
                                     y=train_generator.classes)
# Convert the class weights into a dictionary format for use during training.
class_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}

# Set up the EarlyStopping callback to halt training if the validation loss does not improve,
# while also restoring the best model weights observed during training.
early_stop = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)  # Patience increased for greater stability.
# Configure the ReduceLROnPlateau callback to lower the learning rate when progress stalls,
# which can help the model converge to a more optimal solution.
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=6, min_lr=1e-6)  # Patience increased for gradual learning rate decay.

# Begin training the model using the training data generator.
# The model is trained for up to 100 epochs with class weighting and the defined callbacks.
history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=100,
    class_weight=class_weights_dict,
    callbacks=[early_stop, reduce_lr]
)

# Evaluate the final model performance on the test dataset.
test_loss, test_acc = model.evaluate(test_generator)
print(f"Test Accuracy: {test_acc:.2f}")

# Generate predictions for the test set.
y_pred = model.predict(test_generator)
# Convert the predicted probabilities to discrete class labels.
y_pred_classes = np.argmax(y_pred, axis=1)
# Retrieve the true class labels from the test generator.
y_true = test_generator.classes

# Create a confusion matrix to visualize the performance across different classes.
cm = metrics.confusion_matrix(y_true, y_pred_classes)
plt.figure(figsize=(8, 6))
# Extract class names from the training data generator.
class_names = list(train_generator.class_indices.keys())
# Plot the confusion matrix as a heatmap for clear visualization.
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()

# Print a detailed classification report including precision, recall, and F1-score for each class.
print(metrics.classification_report(y_true, y_pred_classes, target_names=class_names))

# Plot the training and validation loss over epochs to assess convergence and detect overfitting.
plt.figure(figsize=(8, 6))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Plot the training and validation accuracy over epochs to evaluate performance improvements.
plt.figure(figsize=(8, 6))
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Prepare to plot ROC curves by converting true labels into one-hot encoded format.
n_classes = 3
y_true_bin = tf.keras.utils.to_categorical(y_true, num_classes=n_classes)
fpr, tpr, roc_auc = {}, {}, {}

# Compute the ROC curve and AUC for each class to evaluate the model's discrimination capability.
for i in range(n_classes):
    fpr[i], tpr[i], _ = metrics.roc_curve(y_true_bin[:, i], y_pred[:, i])
    roc_auc[i] = metrics.auc(fpr[i], tpr[i])

# Plot the ROC curves for each class, including a diagonal line representing random chance.
plt.figure(figsize=(8, 6))
for i, class_name in enumerate(class_names):
    plt.plot(fpr[i], tpr[i], label=f'{class_name} (AUC = {roc_auc[i]:.2f})')
plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line for reference.
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend(loc="lower right")
plt.show()